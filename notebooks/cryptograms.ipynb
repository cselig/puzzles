{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See my blog post [here](https://cselig.github.io/blog/ciphers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from collections import defaultdict\n",
    "from functools import lru_cache, reduce\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../google-10000-english/google-10000-english.txt') as word_file:\n",
    "    dictionary = set(word_file.read().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MESSAGES = [x.lower() for x in\n",
    "    [\n",
    "        'APPF VIBQ KMF EKLC DIM',\n",
    "        'ZCA LIZIQA PV KMZ X EPLZ PZ PV XK XSCPAUAFAKZ AUAQR EAKAQXZPMK CAYTV FXHA PZV MJK LIZIQA ZCPV PV ZCA AVVAKZPXY SCXYYAKEA ML ZCA TQAVAKZ',\n",
    "        \"X WK DBKZ KBF NRXBM HYKTN CF X WKBN CFHVTQF CJVFPA YJ KNRFQV FEUFONHNXKBV KQ PFN KNRFQV WFAXBF CJ ZKQNR\",\n",
    "        'G NQPBSDKBDX TUN BDQLNR XQ NUPB VQL BPBSVXRUDN VQL FGDX UJ G NQPBSDKBDX TUN BDQLNR XQ XGHB YSQK VQL BPBSVXRUDN VQL RGPB',\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ngrams are dictionaries of the triple (ngram, len, i) mapped to a set of\n",
    "# words of length `len` where the character ngram `ngram` appears at index `i`.\n",
    "# By including the word length and index in the key we can narrow down word matches later.\n",
    "ngrams: 'Dict[Tuple[str, int, int], Set[str]]' = defaultdict(set)\n",
    "\n",
    "# words_by_length is a dictionary of word length to set of words\n",
    "words_by_length: 'Dict[int, Set[str]]' = defaultdict(set)\n",
    "    \n",
    "words_to_rank: 'Dict[str, int]' = defaultdict(lambda: 10_001)\n",
    "\n",
    "for i, word in enumerate(dictionary):\n",
    "    words_by_length[len(word)].add(word)\n",
    "    words_to_rank[word] = i\n",
    "    for i in range(0, len(word)):\n",
    "        ngrams[(word[i], len(word), i)].add(word)\n",
    "        if i < len(word) - 1:\n",
    "            ngrams[(word[i:i+2], len(word), i)].add(word)\n",
    "        if i < len(word) - 2:\n",
    "            ngrams[(word[i:i+3], len(word), i)].add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [w.lower() for w in nltk.corpus.gutenberg.words() if w.isalpha()]\n",
    "word_bigrams: 'Dict[Tuple[str, str], int]' = defaultdict(int)\n",
    "for bigram in nltk.bigrams(words):\n",
    "    word_bigrams[bigram] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what fraction of a candidate decoded message's words are found in the dictionary?\n",
    "#\n",
    "# `message` should be lowercase\n",
    "# contractions appear in dictionary without apostrophes e.g. \"wont\", \"shouldnt\"\n",
    "def compute_fraction_in_dictionary(message: str):\n",
    "    message = ''.join([c for c in message if c.isalpha() or c in (' ', '-')])\n",
    "    words = message.split()\n",
    "    in_dict = [w for w in words if w in dictionary]\n",
    "    return len(in_dict) / len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a cipher and an encrypted message, decode the message\n",
    "# a cipher is a mapping between 'encrypted' and 'decrypted' characters\n",
    "def decode(message: str, cipher: 'Dict[str, str]') -> str:\n",
    "    result = ''\n",
    "    for char in message:\n",
    "        if not char.isalpha():\n",
    "            result += char\n",
    "        elif char in cipher:\n",
    "            result += cipher[char]\n",
    "        else:\n",
    "            result += '-'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a cipher is valid if values don't repeat\n",
    "def validate_cipher(cipher: 'Dict[str, str]') -> bool:\n",
    "    return len(cipher.values()) == len(set(cipher.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Higher score is better. Doesn't normalize for message length.\n",
    "def score_cipher(message: str, cipher: 'Dict[str, str]') -> float:\n",
    "    decoded_words = decode(message, cipher).split()\n",
    "    \n",
    "    # by word popularity\n",
    "#     return -1 * sum([words_to_rank[w] for w in decoded_words])\n",
    "    \n",
    "    # by bigram popularity\n",
    "    bigrams = nltk.bigrams(decoded_words)\n",
    "    return sum([word_bigrams[b] for b in bigrams])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=None)\n",
    "def find_words_matching_pattern(template: str) -> 'Set[str]':\n",
    "    # Given a pattern, return words from dictionary that match. \"-\" is a wildcard.\n",
    "    # E.g. \"-ood\" -> {\"good\", \"hood\", ...}\n",
    "    if template.isalpha():\n",
    "        return set([template])\n",
    "\n",
    "    ngram_word_matches: 'List[set]' = []\n",
    "    # look for decoded ngrams\n",
    "    for i in range(0, len(template)):\n",
    "        if template[i].isalpha():\n",
    "            ngram_word_matches.append(ngrams[(template[i], len(template), i)])\n",
    "        if i < len(template) - 1 and template[i:i+2].isalpha():\n",
    "            ngram_word_matches.append(ngrams[(template[i:i+2], len(template), i)])\n",
    "        if i < len(template) - 2 and template[i:i+3].isalpha():\n",
    "            ngram_word_matches.append(ngrams[(template[i:i+3], len(template), i)])\n",
    "\n",
    "    ngram_word_matches = [s for s in ngram_word_matches if len(s) > 0]\n",
    "    if ngram_word_matches:\n",
    "        return reduce(lambda a, b: a & b, ngram_word_matches)\n",
    "    else:\n",
    "        return words_by_length[len(template)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def optimize_cipher(\n",
    "    message: str,\n",
    "    cipher: 'Dict[str, str]',\n",
    ") -> 'List[Tuple[Dict[str, str], float]]':\n",
    "    # Given a message and an incomplete cipher, return a list of\n",
    "    # completed ciphers and their scores.\n",
    "    # Currently doesn't handle any punctuation (periods, apostrophes, etc.)\n",
    "    if not all([c.isalpha() or c == ' ' for c in message]):\n",
    "        raise ValueError(\"Message should only contain letters.\")\n",
    "    message = message.lower()\n",
    "\n",
    "    possible_new_ciphers = generate_possible_new_ciphers(\n",
    "        message.split(),\n",
    "        cipher,\n",
    "    )\n",
    "    scored_ciphers = [(cipher, score_cipher(message, cipher)) for cipher in possible_new_ciphers]\n",
    "    return sorted(scored_ciphers, key=lambda t: t[1], reverse=True)\n",
    "\n",
    "def generate_possible_new_ciphers(\n",
    "    message_words: 'List[str]',\n",
    "    working_cipher: 'Dict[str, str]',\n",
    ") -> 'List[Dict[str, str]]':\n",
    "    # For every word we found a bigram in we now have a set of possible decoded words.\n",
    "    # Each decoded word implies an expanded cipher using the letters that were previously\n",
    "    # encoded, so we return combinations of non-conflicting ciphers.\n",
    "    assert(validate_cipher(working_cipher))\n",
    "\n",
    "    result = []\n",
    "    possible_word_matches = find_words_matching_pattern(decode(message_words[0], working_cipher))\n",
    "    for word in possible_word_matches:\n",
    "        new_cipher = generate_new_cipher(message_words[0], word)\n",
    "        # a valid cipher will not always be generated: e.g. generate_new_cipher(\"abcd\", \"lulu\")\n",
    "        if validate_cipher(new_cipher) and not ciphers_conflict(working_cipher, new_cipher):\n",
    "            new_cipher.update(working_cipher)\n",
    "            if len(message_words) == 1:\n",
    "                result += [new_cipher]\n",
    "            else:\n",
    "                result += generate_possible_new_ciphers(\n",
    "                      message_words[1:],\n",
    "                      copy.copy(new_cipher),\n",
    "                  )\n",
    "    return result\n",
    "\n",
    "\n",
    "def generate_new_cipher(original_word, decoded_word) -> 'Dict[str, str]':\n",
    "    # should actually probably only generate parts of the cipher that are new\n",
    "    assert len(original_word) == len(decoded_word)\n",
    "    cipher = {}\n",
    "    for i in range(0, len(original_word)):\n",
    "        if decoded_word[i] != '-':\n",
    "            cipher[original_word[i]] = decoded_word[i]\n",
    "    return cipher\n",
    "\n",
    "def invert_cipher(cipher: 'Dict[str, str]') -> 'Dict[str, str]':\n",
    "    return {v: k for k, v in cipher.items()}\n",
    "\n",
    "def ciphers_conflict(cipher1: 'Dict[str, str]', cipher2: 'Dict[str, str]') -> bool:\n",
    "    assert(validate_cipher(cipher1) and validate_cipher(cipher2))\n",
    "    cipher1_inverse = invert_cipher(cipher1)\n",
    "    for k, v in cipher2.items():\n",
    "        if (k in cipher1 and v != cipher1[k] or\n",
    "            v in cipher1_inverse and k != cipher1_inverse[v]):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Is cipher1 a subset of cipher2?\n",
    "def cipher_is_subset(cipher1: 'Dict[str, str]', cipher2: 'Dict[str, str]') -> bool:\n",
    "    return all([cipher2.get(k) == cipher1[k] for k in cipher1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "appf vibq kmf eklc dim\n",
      "good luc- --d ---- -u-\n",
      "[('good luck and have run', 339),\n",
      " ('good luck and have fun', 328),\n",
      " ('good luck and have jun', 328),\n",
      " ('good luck and have sun', 328),\n",
      " ('good lucy and have run', 319),\n",
      " ('good lucy and have fun', 308),\n",
      " ('good lucy and have jun', 308),\n",
      " ('good lucy and have sun', 308),\n",
      " ('good lucy and make fun', 190),\n",
      " ('good lucy and make run', 189)]\n"
     ]
    }
   ],
   "source": [
    "cipher = {\n",
    "    'a': 'g',\n",
    "    'p': 'o',\n",
    "    'f': 'd',\n",
    "    'v': 'l',\n",
    "    'i': 'u',\n",
    "    'b': 'c',\n",
    "#     'q': 'k',\n",
    "#     'k': 'a',\n",
    "#     'e': 'h',\n",
    "#     'l': 'v',\n",
    "#     'c': 'e',\n",
    "#     'd': 'f',\n",
    "#     'm': 'n',\n",
    "}\n",
    "print(MESSAGES[0])\n",
    "print(decode(MESSAGES[0], cipher))\n",
    "scored_ciphers = optimize_cipher(MESSAGES[0], cipher)\n",
    "pprint([(decode(MESSAGES[0], x[0]), x[1]) for x in scored_ciphers[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zca liziqa pv kmz x eplz pz pv xk xscpauafakz auaqr eakaqxzpmk caytv fxha pzv mjk liziqa zcpv pv zca avvakzpxy scxyyakea ml zca tqavakz\n",
      "--- ------ -- --- a ---- -- -- a- a---------- ----- -----a---- ----- -a-- --- --- ------ ---- -- --- -------a- --a------ -- --- -------\n",
      "[('the future is not a gift it is an achievement every generation helps make '\n",
      "  'its own future this is the essential challenge of the present',\n",
      "  25831),\n",
      " ('the future is not a gift it is an achievement every generation helps made '\n",
      "  'its own future this is the essential challenge of the present',\n",
      "  25831)]\n"
     ]
    }
   ],
   "source": [
    "cipher = {\n",
    "    'x': 'a',\n",
    "}\n",
    "\n",
    "print(MESSAGES[1])\n",
    "print(decode(MESSAGES[1], cipher))\n",
    "scored_ciphers = optimize_cipher(MESSAGES[1], cipher)\n",
    "pprint([(decode(MESSAGES[1], x[0]), x[1]) for x in scored_ciphers[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x wk dbkz kbf nrxbm hyktn cf x wkbn cfhvtqf cjvfpa yj knrfqv feufonhnxkbv kq pfn knrfqv wfaxbf cj zkqnr\n",
      "i -- ---- --- --i-- ----- -- i ---- ------- ------ -- ------ --------i--- -- --- ------ ---i-- -- -----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'i do know one thing about me i dont measure myself by others expectations or let others define my worth'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cipher = {\n",
    "    'x': 'i',\n",
    "}\n",
    "\n",
    "print(MESSAGES[2])\n",
    "print(decode(MESSAGES[2], cipher))\n",
    "scored_ciphers = optimize_cipher(MESSAGES[2], cipher)\n",
    "decode(MESSAGES[2], scored_ciphers[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g nqpbsdkbdx tun bdqlnr xq nupb vql bpbsvxrudn vql fgdx uj g nqpbsdkbdx tun bdqlnr xq xghb ysqk vql bpbsvxrudn vql rgpb\n",
      "a ---------- --- ------ -- ---- --- ---------- --- -a-- -- a ---------- --- ------ -- -a-- ---- --- ---------- --- -a--\n",
      "[('a government big enough to give you everything you want is a government big '\n",
      "  'enough to take from you everything you have',\n",
      "  3258),\n",
      " ('a government pig enough to give you everything you want is a government pig '\n",
      "  'enough to take from you everything you have',\n",
      "  3246),\n",
      " ('a government dig enough to give you everything you want is a government dig '\n",
      "  'enough to take from you everything you have',\n",
      "  3246),\n",
      " ('a government big enough to give you everything you cant is a government big '\n",
      "  'enough to take from you everything you have',\n",
      "  3173),\n",
      " ('a government pig enough to give you everything you cant is a government pig '\n",
      "  'enough to take from you everything you have',\n",
      "  3161)]\n"
     ]
    }
   ],
   "source": [
    "cipher = {\n",
    "    'g': 'a',\n",
    "}\n",
    "\n",
    "print(MESSAGES[3])\n",
    "print(decode(MESSAGES[3], cipher))\n",
    "scored_ciphers = optimize_cipher(MESSAGES[3], cipher)\n",
    "pprint([(decode(MESSAGES[3], x[0]), x[1]) for x in scored_ciphers[:5]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
